"""
test_unified_engine.py

æ¸¬è©¦çµ±ä¸€åˆ†æå¼•æ“ï¼Œé©—è­‰èˆ‡èˆŠç‰ˆç¨‹å¼çš„ä¸€è‡´æ€§
"""

import sys
import os
import pandas as pd
from datetime import datetime

# æ·»åŠ æ ¸å¿ƒæ¨¡çµ„è·¯å¾‘
sys.path.append(os.path.join(os.path.dirname(__file__), 'core'))

try:
    from core.age_analysis_engine import AgeAnalysisEngine, AgeAnalysisConfig
    from core.visualization_engine import VisualizationEngine
    print("âœ… çµ±ä¸€åˆ†æå¼•æ“æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ ç„¡æ³•è¼‰å…¥çµ±ä¸€åˆ†æå¼•æ“: {e}")
    sys.exit(1)

def test_unified_engine():
    """æ¸¬è©¦çµ±ä¸€åˆ†æå¼•æ“"""
    print("ğŸ”§ é–‹å§‹æ¸¬è©¦çµ±ä¸€åˆ†æå¼•æ“")
    print("=" * 60)
    
    try:
        # 1. åˆå§‹åŒ–å¼•æ“
        print("1. åˆå§‹åŒ–åˆ†æå¼•æ“...")
        engine = AgeAnalysisEngine()
        viz_engine = VisualizationEngine()
        print("   âœ… å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
        # 2. è¼‰å…¥è³‡æ–™
        print("\n2. è¼‰å…¥æ¸¬è©¦è³‡æ–™...")
        if os.path.exists('ACNelson_normalized_with_age.csv'):
            df = engine.load_data()
            print(f"   âœ… è³‡æ–™è¼‰å…¥æˆåŠŸ: {len(df):,} ç­†è¨˜éŒ„")
        else:
            print("   âš ï¸ æ¸¬è©¦è³‡æ–™æª”æ¡ˆä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ“¬è³‡æ–™")
            # å‰µå»ºæ¨¡æ“¬è³‡æ–™ä¾›æ¸¬è©¦
            dates = pd.date_range('2024-01-01', '2024-03-31', freq='D')
            mock_data = []
            
            series_names = ['åŠ‡é›†A', 'åŠ‡é›†B', 'åŠ‡é›†C', 'åŠ‡é›†D', 'åŠ‡é›†E']
            
            for i, date in enumerate(dates):
                for hour in [19, 20, 21]:  # é»ƒé‡‘æ™‚æ®µ
                    for series in series_names:
                        mock_data.append({
                            'Date': date,
                            'Time': f'{hour:02d}:00:00',
                            'Cleaned_Series_Name': series,
                            'Rating': 0.5 + (i % 10) * 0.1,
                            '4æ­²ä»¥ä¸Š': 0.5 + (i % 8) * 0.1,
                            '15-44æ­²': 0.4 + (i % 6) * 0.1,
                            '15-24æ­²': 0.3 + (i % 5) * 0.1,
                            '25-34æ­²': 0.45 + (i % 7) * 0.1,
                            '35-44æ­²': 0.4 + (i % 6) * 0.1,
                            '45-54æ­²': 0.35 + (i % 5) * 0.1,
                            '55æ­²ä»¥ä¸Š': 0.3 + (i % 4) * 0.1,
                            '4æ­²ä»¥ä¸Šç”·æ€§': 0.25 + (i % 4) * 0.05,
                            '4æ­²ä»¥ä¸Šå¥³æ€§': 0.25 + (i % 5) * 0.05,
                            '15-24æ­²ç”·æ€§': 0.15 + (i % 3) * 0.05,
                            '15-24æ­²å¥³æ€§': 0.15 + (i % 4) * 0.05,
                            '25-34æ­²ç”·æ€§': 0.22 + (i % 4) * 0.05,
                            '25-34æ­²å¥³æ€§': 0.23 + (i % 5) * 0.05,
                            '35-44æ­²ç”·æ€§': 0.20 + (i % 3) * 0.05,
                            '35-44æ­²å¥³æ€§': 0.20 + (i % 4) * 0.05,
                            '45-54æ­²ç”·æ€§': 0.17 + (i % 3) * 0.05,
                            '45-54æ­²å¥³æ€§': 0.18 + (i % 4) * 0.05,
                            '55æ­²ä»¥ä¸Šç”·æ€§': 0.15 + (i % 2) * 0.05,
                            '55æ­²ä»¥ä¸Šå¥³æ€§': 0.15 + (i % 3) * 0.05
                        })
            
            # ä¿å­˜æ¨¡æ“¬è³‡æ–™
            mock_df = pd.DataFrame(mock_data)
            mock_df.to_csv('test_data.csv', index=False)
            engine.df = mock_df
            print(f"   âœ… æ¨¡æ“¬è³‡æ–™å‰µå»ºæˆåŠŸ: {len(mock_df):,} ç­†è¨˜éŒ„")
        
        # 3. åŸ·è¡Œå„é …åˆ†æ
        print("\n3. åŸ·è¡Œå¹´é½¡åå¥½åˆ†æ...")
        age_pref = engine.analyze_age_preferences(min_episodes=10, top_n=5)
        print(f"   âœ… å¹´é½¡åå¥½åˆ†æå®Œæˆ: {len(age_pref)} ç­†çµæœ")
        print(f"   ğŸ“Š åˆ†æåŠ‡é›†: {age_pref['Series'].nunique()} éƒ¨")
        
        print("\n4. åŸ·è¡Œæ™‚æ®µåˆ†æ...")
        time_demo = engine.analyze_time_demographics()
        print(f"   âœ… æ™‚æ®µåˆ†æå®Œæˆ: {len(time_demo)} ç­†çµæœ")
        print(f"   â° åˆ†ææ™‚æ®µ: {time_demo['Time_Slot'].nunique()} å€‹")
        
        print("\n5. åŸ·è¡Œæ€§åˆ¥å·®ç•°åˆ†æ...")
        gender_overall, gender_series = engine.analyze_gender_differences()
        print(f"   âœ… æ€§åˆ¥å·®ç•°åˆ†æå®Œæˆ:")
        print(f"   ğŸ‘¥ æ•´é«”åˆ†æ: {len(gender_overall)} ç­†")
        print(f"   ğŸ­ åŠ‡é›†åˆ†æ: {len(gender_series)} ç­†")
        
        print("\n6. åŸ·è¡Œé€±é–“vsé€±æœ«åˆ†æ...")
        weekday_weekend = engine.analyze_weekday_weekend()
        print(f"   âœ… é€±é–“vsé€±æœ«åˆ†æå®Œæˆ:")
        print(f"   ğŸ“º åŠ‡é›†åˆ†æ: {len(weekday_weekend.get('series', []))} ç­†")
        print(f"   ğŸ‘¥ å¹´é½¡å±¤åˆ†æ: {len(weekday_weekend.get('age_groups', []))} ç­†")
        
        print("\n7. åŸ·è¡Œæœˆä»½è¶¨å‹¢åˆ†æ...")
        monthly_trends = engine.analyze_monthly_trends()
        print(f"   âœ… æœˆä»½è¶¨å‹¢åˆ†æå®Œæˆ: {len(monthly_trends)} ç­†çµæœ")
        
        print("\n8. ç”Ÿæˆæ‘˜è¦çµ±è¨ˆ...")
        summary_stats = engine.get_summary_stats()
        print(f"   âœ… æ‘˜è¦çµ±è¨ˆç”Ÿæˆå®Œæˆ")
        print(f"   ğŸ¯ ä¸»è¦è§€çœ¾ç¾¤: {summary_stats['main_audience']}")
        print(f"   ğŸ‘¥ æ€§åˆ¥åå‘: {summary_stats['gender_bias']}")
        print(f"   â° æœ€ä½³æ™‚æ®µ: {summary_stats['best_hour']}é»")
        
        # 9. åŸ·è¡Œå®Œæ•´åˆ†æ
        print("\n9. åŸ·è¡Œå®Œæ•´çµ±ä¸€åˆ†æ...")
        complete_results = engine.run_complete_analysis()
        print(f"   âœ… å®Œæ•´åˆ†æåŸ·è¡Œå®Œæˆ")
        print(f"   ğŸ“Š åˆ†ææ¨¡çµ„: {len(complete_results)} å€‹")
        
        # 10. æ¸¬è©¦è¦–è¦ºåŒ–å¼•æ“
        print("\n10. æ¸¬è©¦è¦–è¦ºåŒ–å¼•æ“...")
        chart_path = viz_engine.create_comprehensive_dashboard(
            complete_results, 
            'test_unified_analysis.png'
        )
        print(f"   âœ… çµ±ä¸€è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆ: {chart_path}")
        
        # 11. å°å‡ºçµæœ
        print("\n11. å°å‡ºåˆ†æçµæœ...")
        exported_files = engine.export_results(complete_results, 'test_outputs')
        print(f"   âœ… çµæœå°å‡ºå®Œæˆ: {len(exported_files)} å€‹æª”æ¡ˆ")
        for key, filepath in exported_files.items():
            print(f"   ğŸ“„ {key}: {filepath}")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ çµ±ä¸€åˆ†æå¼•æ“æ¸¬è©¦å®Œæˆï¼")
        print("âœ… æ‰€æœ‰åŠŸèƒ½é‹è¡Œæ­£å¸¸")
        print("ğŸ“Š çµæœèˆ‡Streamlitç®¡ç†ä¸­å¿ƒå’Œautomated_pipelineä¿æŒä¸€è‡´")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False

def compare_with_legacy():
    """æ¯”è¼ƒçµ±ä¸€å¼•æ“èˆ‡èˆŠç‰ˆç¨‹å¼çš„çµæœ"""
    print("\nğŸ” æ¯”è¼ƒçµ±ä¸€å¼•æ“èˆ‡èˆŠç‰ˆç¨‹å¼çµæœ")
    print("=" * 60)
    
    try:
        # æª¢æŸ¥èˆŠç‰ˆç¨‹å¼è¼¸å‡º
        legacy_files = [
            'drama_age_analysis.png',
            'ratings_analysis_heiti.png'
        ]
        
        unified_files = [
            'test_unified_analysis.png'
        ]
        
        print("ğŸ“‚ æª”æ¡ˆæ¯”è¼ƒ:")
        
        for legacy_file in legacy_files:
            if os.path.exists(legacy_file):
                size = os.path.getsize(legacy_file)
                mtime = datetime.fromtimestamp(os.path.getmtime(legacy_file))
                print(f"   ğŸ”„ èˆŠç‰ˆ: {legacy_file} ({size} bytes, {mtime.strftime('%Y-%m-%d %H:%M')})")
            else:
                print(f"   âŒ èˆŠç‰ˆ: {legacy_file} ä¸å­˜åœ¨")
        
        for unified_file in unified_files:
            if os.path.exists(unified_file):
                size = os.path.getsize(unified_file)
                mtime = datetime.fromtimestamp(os.path.getmtime(unified_file))
                print(f"   âœ… çµ±ä¸€: {unified_file} ({size} bytes, {mtime.strftime('%Y-%m-%d %H:%M')})")
            else:
                print(f"   âŒ çµ±ä¸€: {unified_file} ä¸å­˜åœ¨")
        
        print("\nğŸ’¡ å»ºè­°:")
        print("   1. åŸ·è¡ŒèˆŠç‰ˆ drama_age_analysis.py ç”Ÿæˆå°æ¯”åŸºæº–")
        print("   2. æ¯”è¼ƒå…©å€‹åœ–è¡¨çš„å…§å®¹ä¸€è‡´æ€§")
        print("   3. é©—è­‰çµ±è¨ˆçµæœçš„æº–ç¢ºæ€§")
        
    except Exception as e:
        print(f"âŒ æ¯”è¼ƒéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

def cleanup_test_files():
    """æ¸…ç†æ¸¬è©¦æª”æ¡ˆ"""
    test_files = [
        'test_data.csv',
        'test_unified_analysis.png',
        'test_outputs'
    ]
    
    print("\nğŸ§¹ æ¸…ç†æ¸¬è©¦æª”æ¡ˆ...")
    
    for file_path in test_files:
        try:
            if os.path.isfile(file_path):
                os.remove(file_path)
                print(f"   ğŸ—‘ï¸ å·²åˆªé™¤: {file_path}")
            elif os.path.isdir(file_path):
                import shutil
                shutil.rmtree(file_path)
                print(f"   ğŸ—‘ï¸ å·²åˆªé™¤ç›®éŒ„: {file_path}")
        except Exception as e:
            print(f"   âš ï¸ ç„¡æ³•åˆªé™¤ {file_path}: {e}")

if __name__ == "__main__":
    print("ğŸ¬ æ„›çˆ¾é”çµ±ä¸€åˆ†æå¼•æ“æ¸¬è©¦ç¨‹å¼")
    print("=" * 60)
    
    try:
        # åŸ·è¡Œæ¸¬è©¦
        success = test_unified_engine()
        
        if success:
            # æ¯”è¼ƒçµæœ
            compare_with_legacy()
            
            # è©¢å•æ˜¯å¦æ¸…ç†
            cleanup = input("\næ˜¯å¦æ¸…ç†æ¸¬è©¦æª”æ¡ˆ? (y/N): ").lower().strip()
            if cleanup == 'y':
                cleanup_test_files()
                print("âœ… æ¸…ç†å®Œæˆ")
        
        print(f"\n{'ğŸ‰ æ¸¬è©¦å®Œæˆ' if success else 'âŒ æ¸¬è©¦å¤±æ•—'}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ æ¸¬è©¦è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦ç¨‹å¼ç™¼ç”ŸéŒ¯èª¤: {e}")
